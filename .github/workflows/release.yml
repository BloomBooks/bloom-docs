name: Notion->Crowdin->Publish
on:
  push:
    branches:
      - master
  workflow_dispatch:
    inputs:
      logLevel:
        description: "Log level"
        required: true
        default: "warning"
jobs:
  release:
    name: Release
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: lts/*
      - name: Install dependencies
        run: yarn install
        # for some reason it was telling me my lockfile was out of date run: yarn install --frozen-lockfile
      - name: Pull from Notion
        env:
          SIL_BLOOM_DOCS_NOTION_TOKEN: ${{ secrets.SIL_BLOOM_DOCS_NOTION_TOKEN }}
          SIL_BLOOM_DOCS_NOTION_ROOT_PAGE: ${{ secrets.SIL_BLOOM_DOCS_NOTION_ROOT_PAGE }}
        run: yarn pull
      - name: copy-static-docs
        run: yarn copy-static-docs
      - name: Commit New Source Material
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: GHAction - Commit content changes pulled from notion

      # We don't have enough translated yet to make it even worth downloading and processing the translations.
      # For now, we skip (comment out) those bits.
      # When reinstating this, be sure to also 
      #  - reenable pdf uploads for fr and es below and in other GHA workflow files
      #  - turn on the relevant locales in docusaurus.config.js
      #  - create (or duplicate from English) localized pdfs in make-pdf.sh

      # - name: Crowdin
      #   run: yarn crowdin:sync
      #   env:
      #     SIL_BLOOM_DOCS_CROWDIN_TOKEN: ${{ secrets.SIL_BLOOM_DOCS_CROWDIN_TOKEN }}
      # - name: Commit New Translations
      #   uses: stefanzweifel/git-auto-commit-action@v5
      #   with:
      #     commit_message: GHAction - Commit incoming translations from Crowdin

      - name: Build Docusaurus instance
        run: yarn build
      - name: Upload S3
        # We exclude these five paths because they existed before the current system.
        # The five index.html files contain redirects. One is to an external document; the others to pages at docs.bloomlibrary.org.
        # See more detailed notes at https://docs.google.com/document/d/1Vub0SeQL6BQqyGoQBN6-cfi6AIRbcBHeV87KjnzZXDU/edit#heading=h.aaxpksot3akz.
        run: aws s3 sync ./build  s3://${{ secrets.AWS_BUCKET }} --delete --exclude "sil-corporate-guidelines/index.html" --exclude "bloom-reader-shelves/index.html" --exclude "team-collections-sharing-services/index.html" --exclude "team-collections/index.html" --exclude "widgets/index.html"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: "us-east-1"
      - name: Disable AppArmor
        # Ubuntu >= 23 has AppArmor enabled by default, which breaks Puppeteer.
        # See https://github.com/puppeteer/puppeteer/issues/12818 "No usable sandbox!"
        # this is taken from the solution used in Puppeteer's own CI: https://github.com/puppeteer/puppeteer/pull/13196
        # The alternative is to pin Ubuntu 22 or to use aa-exec to disable AppArmor for commands that need Puppeteer.
        # This is also suggested by Chromium https://chromium.googlesource.com/chromium/src/+/main/docs/security/apparmor-userns-restrictions.md
        run: echo 0 | sudo tee /proc/sys/kernel/apparmor_restrict_unprivileged_userns
        shell: bash
      # Make and upload the PDF after uploading to S3 since the PDF is created from content on S3.
      - name: Generate PDFs
        run: yarn make-pdf
      - name: Upload PDFs to S3
        run: aws s3 cp ./build/downloads/ s3://${{ secrets.AWS_BUCKET }}/downloads/ --recursive --exclude "*" --include "*.pdf"
          # aws s3 cp ./build/fr/downloads/ s3://${{ secrets.AWS_BUCKET }}/fr/downloads/ --recursive --exclude "*" --include "*.pdf"
          # aws s3 cp ./build/es/downloads/ s3://${{ secrets.AWS_BUCKET }}/es/downloads/ --recursive --exclude "*" --include "*.pdf"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: "us-east-1"
      - name: Cloudflare - purge cache for PDFs
        uses: jakejarvis/cloudflare-purge-action@v0.3.0
        env:
          CLOUDFLARE_ZONE: ${{ secrets.CLOUDFLARE_ZONE }}
          CLOUDFLARE_TOKEN: ${{ secrets.CLOUDFLARE_TOKEN }}
          PURGE_URLS: '["https://docs.bloomlibrary.org/downloads/docs-bloomlibrary-english-a4.pdf", "https://docs.bloomlibrary.org/fr/downloads/docs-bloomlibrary-english-a4.pdf", "https://docs.bloomlibrary.org/es/downloads/docs-bloomlibrary-english-a4.pdf"]'
